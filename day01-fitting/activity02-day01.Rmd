---
title: "Activity 2 - Day 1"
output: github_document
---

```{setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
library(readr)
```


## Task 3: Load the data and

```{r load-data, warning=FALSE}
hfi <- read_csv("https://www.openintro.org/data/csv/hfi.csv");

glimpse(hfi)

head(hfi)
```

After doing this and viewing the loaded data, answer the following
questions:

1.  What are the dimensions of the dataset? What does each row
    represent?
    
    123 variables and 1458 observations.

- The dataset spans a lot of years. We are only interested in data from
  year 2016.
  - Create a new R code chunk,
  - Filter the data `hfi` data frame for year 2016, and
  - Assign the result to a data frame named `hfi_2016`.
  
```{r}
hfi_2016 <- hfi %>% filter(year == 2016)
head(hfi_2016)
```


2.  What type of plot would you use to display the relationship between
    the personal freedom score, `pf_score`, and `pf_expression_control`?

- Create a new R code chunk and plot this relationship using the
  variable `pf_expression_control` as the predictor.
  
```{r}
hfi_2016 %>% ggplot(aes(pf_expression_control, pf_score)) +
  geom_point() +
  labs(
    title = "pf_expression_control vs pf_score for year 2016",
    x = "pf_expression_control",
    y = "pf_score"
  )
```


3.  Does the relationship look linear? If you knew a countryâ€™s
    `pf_expression_control`, or its score out of 10, with 0 being the
    most, of political pressures and controls on media content, would
    you be comfortable using a linear model to predict the personal
    freedom score?
    
    The relationship looks positively linear. Based on above graph, linear model should be sufficient.
    
    
## Task 4: Sum of squared residuals

## Task 5: The linear model

```{r}
m1 <- lm(pf_score ~ pf_expression_control, data = hfi_2016)
tidy(m1)
```

The y-intercept is 4.28 and slope is 0.541

## Day2: Accessing the Model

```{r dplry}
hfi_2016 %>%
  summarize(cor=cor(pf_score,pf_expression_control))
```

Positive correlation among the variables.

```{r rsquared}
glance(m1)
```

The r-square is 0.714(`71%` accuracy.)

## New Model

```{r hf-model}
m2 <- lm(hf_score ~ pf_expression_control, data = hfi_2016)
tidy(m2)
```

### Prediction and prediction errors
```{r plot task 3}
hfi_2016 %>% 
  ggplot(aes(x=pf_expression_control, y=pf_score)) +
  geom_smooth(method = "lm", se = FALSE) +
  geom_point() + 
  theme_bw() + 
  ggtitle('pf_score vs. pf_expression_control')
```

### Model Diagnostics
```{r augment}
m1_aug <- augment(m1)
```

```{r residual chart}
ggplot(data = m1_aug, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  xlab("Fitted values") +
  ylab("Residuals") + 
  theme_bw()
```
The residuals look like they have constant variance until the higher predicted values where variance seems to decrease.

```{r histogram}
ggplot(data = m1_aug, aes(x = .resid)) +
  geom_histogram(binwidth = 0.25) +
  xlab("Residuals") + 
  theme_bw()
```
The histogram is slightly skewed which suggest that variablility appears to be violated.

### Challange: More Practice

```{r another variable}
hfi_2016 %>%
  ggplot(aes(x = pf_expression_influence, y = pf_score)) +
  geom_point()
  
m3 <- lm(pf_score ~ pf_expression_influence, data = hfi_2016)
tidy(m3)
glance(m3)
```
